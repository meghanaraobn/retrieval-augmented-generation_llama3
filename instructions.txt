**Prerequisites
    - Linux or macOS (recommended)
    - Python 3
    - NVIDIA GPU + CUDA CuDNN

**Project Structure
    .
    ├── app
    │   ├── main.py
    │   ├── index_manager.py
    │   ├── index_query_service.py
    │   ├── index_service_context_loader.py
    │   ├── scripts
    │   │   └── extract_citations.py
    ├── docs
    │   └── index
    │   └── scientific_papers
    ├── environment.yml
    ├── Dockerfile
    ├── docker-compose.yml
    ├── requirements.txt
    ├── .env
    └── instructions.txt

**Getting Started
    - For pip users, please type the command ---> pip install -r requirements.txt
    - For conda users, you can create a new conda environment using ---> conda env create -f environment.yml
    - Docker Support
        - Build the docker image ---> docker-compose build
        - To spin the container ---> docker-compose up -d
        - To enter into the container (rag-container) ---> docker exec -it rag-container bash
        - To stop the container ---> docker-compose down
    
    - Set up hugging face token in .env file ---> HF_TOKEN=huggingface_token
    - Place all the documents (.pdf files) in the directory: '/docs/scientific_papers'
    - If you have a persisted index, place it in the directory: '/docs/index'
    - Start the FastAPI application ---> uvicorn app.main:app --reload
        - Navigate to swagger UI ---> http://127.0.0.1:8000/docs

**Endpoints
    - Root Endpoint: 'GET /'
    - Create Document Index: 'POST /create_index' (parameter - document_path)
    - Delete Document Index: 'DELETE /delete_index/{ref_document_id}' (parameter - ref_document_id)
    - Query Documents: 'POST /query_documents' (parameter - query_string)

**Other Information 
    - API used: FastAPI
    - LLM used: Meta-Llama-3-8B-Instruct
    - Embed model used: all-mpnet-base-v2
    - For indexing: llama_index

    - Process Flow: 
        - Startup
        - Load environment variables
        - Hugging face login 
        - Service context set up (configured with LLM, embedding model)
        - Initially index all documents present in '/docs/scientific_papers' 
          (if persisted index is present, load the index present in '/docs/index') 
        - Create index/Delete index/Query documents.
    
    - When deleting a document from the index, its ref_document_id must be fetched from '/docs/index/docstore.json'. 
      Documents are deleted from the index based on their ref_document_id, as this is the identifier used by llama_index for management.

**Further improvements
    - Improve index management to handle large volumes of documents more efficiently.
    - Fine-tune the Meta-Llama-3-8B-Instruct model.
    - Create a broader range of prompts to cover more use cases which improve the LLM's ability to handle different queries.
    - Improve techniques for citation extraction from the retrieved source text.

